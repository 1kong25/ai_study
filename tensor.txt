- PyTorch에서는 텐서를 사용하여 모델의 입력(input)과 출력(output), 그리고 모델의 매개변수들을 부호화(encode)

# 텐서 초기화
1. 데이터로부터 직접 생성
data=[[1,2],[3,4]]
x_data = torch.tensor(data)
2. NumPy 배열로부터 생성
np_array = np.array(data)
x_np = torch.from_numpy(np_array)
3. 다른 텐서로부터 생성
4. 무작위 또느 상수 값 사용
- 각 연산들은 (일반적으로 CPU보다 빠른) GPU에서 실행할 수 있다. Colab을 사용한다면, Edit > Notebook Settings 에서 GPU를 할당할 수 있다.

# GPU가 존재하면 텐서 명시적으로 이동 가능
if torch.cuda.is_available():
    tensor = tensor.to('cuda')

# 두 텐서 간의 행렬 곱(matrix multiplication)을 계산. y1, y2, y3은 모두 같은 값을 가짐.
y1 = tensor @ tensor.T
y2 = tensor.matmul(tensor.T)

y3 = torch.rand_like(tensor)
torch.matmul(tensor, tensor.T, out=y3)


# 요소별 곱(element-wise product)을 계산. z1, z2, z3는 모두 같은 값을 가짐.
z1 = tensor * tensor
z2 = tensor.mul(tensor)

z3 = torch.rand_like(tensor)
torch.mul(tensor, tensor, out=z3)

# NumPy 변환 (CPU 상의 텐서와 NumPy 배열은 메모리 공간을 공유하기 때문에, 하나를 변경하면 다른 하나도 변경)
- 텐서를 NumPy로 변환
t = torch.ones(5)
print(f"t: {t}")
n = t.numpy()
print(f"n: {n}")
--------out--------
t: tensor([1., 1., 1., 1., 1.])
n: [1. 1. 1. 1. 1.]

- NumPy를 텐서로 변환
n = np.ones(5)
t = torch.from_numpy(n)
np.add(n, 1, out=n)
print(f"t: {t}")
print(f"n: {n}")
--------out--------
t: tensor([2., 2., 2., 2., 2.], dtype=torch.float64)
n: [2. 2. 2. 2. 2.]
